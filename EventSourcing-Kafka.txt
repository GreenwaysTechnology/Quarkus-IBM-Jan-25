.....................................................................................
		  Event Sourcing with Kafka( Any Message Broker)
.....................................................................................
Storing events into db may  not be suitable most of the use cases, so we need to store events into event store.

Event Store:
  The software/infrastructure which primarily designed for storing events.

Event Store Products:

1.Apache/Confluent Kafka
   Most popular events storage software.

2.event store: https://www.eventstore.com/
  It is also one of the software Primarily used to store events.

3.Most of the cloud providers also offers event storage
  eg
   google pub-sub.

4.RabbitMq, IBM MQ

5.Redis message Broker
etc....

Our implementation is Kafka.
.....................................................................................		         Domain Event and Event Sourcing Design Pattern
			      Implementation
		 (SmallRye Reactive Messaging Specification)
.....................................................................................
In spring we have Spring Cloud Stream..

SmallRye Reactive Messaging Specification:
..........................................
SmallRye Reactive Messaging is a framework for building event-driven, data streaming, and event-sourcing applications using CDI.

 It lets your application interaction using various messaging technologies such as Apache Kafka, AMQP or MQTT. The framework provides a flexible programming model bridging CDI and event-driven.


Our Implementation Could be Apache Kafka:
..........................................

Apache Kafka is a popular open-source distributed event streaming platform. It is used commonly for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications. Similar to a message queue, or an enterprise messaging platform, it lets you:


1.publish (write) and subscribe to (read) streams of events, called records.

2.store streams of records durably and reliably inside topics.

3.process streams of records as they occur or retrospectively.


Core Concepts of SmallRye Reactive Messaging:
....................................

1.Message:
..........
Applications send and receive messages. A message wraps a payload and can be extended with some metadata. With the Kafka connector, a message corresponds to a Kafka record.


2.Channels:
 Messages transit on channels. Application components connect to channels to publish and consume messages. The Kafka connector maps channels to Kafka topics.

3.Connectors:
  Channels are connected to message backends using connectors.
Connectors are configured to map incoming messages to a specific channel (consumed by the application) and collect outgoing messages sent to a specific channel. Each connector is dedicated to a specific messaging technology. For example, the connector dealing with Kafka is named smallrye-kafka.

....................................................................................
			 Connectors

Connectors:
  Reactive Messaging can handle messages generated from within the application but also interact with remote brokers. Reactive Messaging Connectors interacts with these remote brokers to retrieve messages and send messages using various protocols and technology.

Each connector handles to a specific technology. For example, a Kafka Connector is responsible for interacting with Kafka, while an MQTT Connector is responsible for MQTT interactions.

Connector name:
...............
Each connector has a name. This name is referenced by the application to indicate that this connector manages a specific channel.

For example, the SmallRye Kafka Connector is named: smallrye-kafka

Types of Connectors:
....................

Inbound and Outbound connectors

Connector can:
1.retrieve messages from a remote broker (inbound)

2.send messages to a remote broker (outbound)

3.A connector can, of course, implement both directions.InBound and OutBound.

.........................................................................

Role of InBound connector:
..........................

1.Inbound connectors are responsible for:

	1..1.Getting messages from the remote broker,

	1.2.Creating a Reactive Messaging "Message" associated with the retrieved 	message.

	1.3.Potentially associating technical metadata with the message.
	   It includes unmarshalling the payload.

	1.4.Associating an acknowledgment callback to acknowledge the incoming 	   message when the Reactive Messaging message is processed/acknowledged.


Role of OutBound Connector:

Outbound connectors are responsible for:

	1.1.Receiving Reactive Messaging Message and transform it into a structure             understood by the remote broker. It includes marshaling the payload.

	1.2..If the Message contains outbound metadata (metadata set during the 	     processing to influence the outbound structure and routing), taking them              into account.

        1.3.Sending the message to the remote broker.

	1.4. Acknowledging the Reactive Messaging Message when the broker has              accepted/acknowledged the message.

Configuring Connectors:
......................
Configuration is done in application.properties 

mp.messaging.[incoming|outgoing].[channel-name].[attribute]=[value]

eg:
mp.messaging.incoming.dummy-incoming-channel.connector=dummy (kafka)
mp.messaging.incoming.dummy-incoming-channel.attribute=value
 
mp.messaging.outgoing.dummy-outgoing-channel.connector=dummy (RabbitMq)
mp.messaging.outgoing.dummy-outgoing-channel.attribute=value


Mapping Channels In the Code:
.............................
  We use annotations to map channels

eg:
mp.messaging.incoming.prices.connector=smallrye-kafka       
mp.messaging.incoming.prices.value.deserializer=org.apache.kafka.common.serialization.DoubleDeserializer    
mp.messaging.incoming.prices.broadcast=true 


@Incoming:
//////////
The [incoming|outgoing] segment indicates the direction.

	an incoming channel consumes data from a message broker or something producing data.
     It’s an inbound interaction. It relates to methods annotated with an @Incoming using the same channel name.

@Outgoing:
	an outgoing consumes data from the application and forwards it to a message broker or something consuming data. 
	It’s an outbound interaction.
 It relates to methods annotated with an @Outgoing using the same channel name.

Channel Name:
..............
 The [channel-name] is the name of the channel. 
  If the channel name contains a . (dot), you would need to use " (double-quote) around it. For example, to configure the dummy.incoming.channel channel, you would need:

mp.messaging.incoming."dummy.incoming.channel".connector=dummy
mp.messaging.incoming."dummy.incoming.channel".attribute=value


Attributes:
..........
 The [attribute]=[value] sets a "specific connector" attribute to the given value. Attributes depend on the used connector. So, refer to the connector documentation to check the supported attributes.

https://smallrye.io/smallrye-reactive-messaging/latest/kafka/writing-kafka-records/#configuration-reference

Here is an example of a channel using an MQTT connector, consuming data from a MQTT broker, and a channel using a Kafka connector (writing data to Kafka):

# [Channel - health] - Consume data from MQTT

mp.messaging.incoming.health.topic=neo
mp.messaging.incoming.health.connector=smallrye-mqtt
mp.messaging.incoming.health.host=localhost
mp.messaging.incoming.health.broadcast=true
# [/Channel - health]

# [Channel - data] - Produce data to Kafka
mp.messaging.outgoing.data.connector=smallrye-kafka
mp.messaging.outgoing.data.bootstrap.servers=localhost:9092
mp.messaging.outgoing.data.key.serializer=org.apache.kafka.common.serialization.StringSerializer
mp.messaging.outgoing.data.value.serializer=io.vertx.kafka.client.serialization.JsonObjectSerializer
mp.messaging.outgoing.data.acks=1
# [/Channel - data]

...................................................................................
			  Receiving Messages from the Kafka
...................................................................................


1.Listener Pattern:
 Just declare method inside class , declare that method as listener... and read messages.


import org.eclipse.microprofile.reactive.messaging.Incoming;

import jakarta.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceConsumer {

    @Incoming("prices")
    public void consume(double price) {
        // process your price.
    }

}
Different ways of consuming messages:
.....................................

@Incoming("prices")
public CompletionStage<Void> consume(Message<Double> msg) {
    // access record metadata
    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();
    // process the message payload.
    double price = msg.getPayload();
    // Acknowledge the incoming message (commit the offset)
    return msg.ack();
}

Kafka stores data as records:

if you want to access Kafka Records directly...

@Incoming("prices")
public void consume(ConsumerRecord<String, Double> record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
    String topic = record.topic();
    int partition = record.partition();
    // ...
}

2.Dependency Injection Pattern:

 Channels can be injected into class and we can read messages...

import io.smallrye.mutiny.Multi;
import org.eclipse.microprofile.reactive.messaging.Channel;
import jakarta.inject.Inject;
import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.Produces;
import jakarta.ws.rs.core.MediaType;
import org.jboss.resteasy.reactive.RestStreamElementType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("prices")
    Multi<Double> prices;

    @GET
    @RestStreamElementType(MediaType.TEXT_PLAIN)
    public Multi<Double> stream() {
        return prices;
    }
}

@Inject @Channel("prices") Multi<Double> streamOfPayloads;

@Inject @Channel("prices") Multi<Message<Double>> streamOfMessages;

@Inject @Channel("prices") Publisher<Double> publisherOfPayloads;

@Inject @Channel("prices") Publisher<Message<Double>> publisherOfMessages;
.....................................................................................

.....................................................................................
			 Sending Messages To Kafka
.....................................................................................

Configuration :

%prod.kafka.bootstrap.servers=kafka:9092 
mp.messaging.outgoing.prices-out.connector=smallrye-kafka 
mp.messaging.outgoing.prices-out.topic=prices 

prices-out - channel Name where we publish Records/Messages.

How to map out going channal.

import io.smallrye.mutiny.Multi;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import jakarta.enterprise.context.ApplicationScoped;
import java.time.Duration;
import java.util.Random;

@ApplicationScoped
public class KafkaPriceProducer {

    private final Random random = new Random();

    @Outgoing("prices-out")
    public Multi<Double> generate() {
        // Build an infinite stream of random prices
        // It emits a price every second
        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -> random.nextDouble());
    }

}

Note:
  You should not call methods annotated with @Incoming and @Outgoing directly from   your   code.

Note that the generate method returns a Multi<Double>, which implements the Reactive Streams Publisher interface. This publisher will be used by the framework to generate messages and send them to the configured Kafka topic.

Different Syntax:
@Outgoing("out")
public Multi<Record<String, Double>> generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
        .map(x -> Record.of("my-key", random.nextDouble()));
}

@Outgoing("generated-price")
public Multi<Message<Double>> generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -> Message.of(random.nextDouble())
                    .addMetadata(OutgoingKafkaRecordMetadata.<String>builder()
                            .withKey("my-key")
                            .withTopic("my-key-prices")
                            .withHeaders(new RecordHeaders().add("my-header", "value".getBytes()))
                            .build()));
}

...................................................................................
			How to push messages from the Rest api
....................................................................................

@Emitter
Sending messages with @Emitter:

Sometimes, you need to have an imperative way of sending messages.

For example, if you need to send a message to a stream when receiving a POST request inside a REST endpoint. In this case, you cannot use @Outgoing because your method has parameters.

For this, you can use an Emitter.

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import jakarta.inject.Inject;
import jakarta.ws.rs.POST;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.Consumes;
import jakarta.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    Emitter<Double> priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        CompletionStage<Void> ack = priceEmitter.send(price);
    }
}
....................................................................................

....................................................................................

How to send Message with ack?

import org.eclipse.microprofile.reactive.messaging.Channel;

import jakarta.inject.Inject;
import jakarta.ws.rs.POST;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.Consumes;
import jakarta.ws.rs.core.MediaType;

import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    MutinyEmitter<Double> priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public Uni<String> addPrice(Double price) {
        return quoteRequestEmitter.send(price)
                .map(x -> "ok")
                .onFailure().recoverWithItem("ko");
    }
}
.....................................................................................